{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Dropout, Input, Flatten, Dense, Lambda, Add, Multiply\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def showImage(image, isGray=False):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "140\n",
      "(140, 128, 128, 1)\n",
      "(140, 50)\n",
      "(140, 50)\n"
     ]
    }
   ],
   "source": [
    "'''Orginalne obrazki'''\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"top_level_file.txt\"))\n",
    "\n",
    "POINTS_DIR = ROOT_DIR + \"/Images/Points/points/*.dat\"\n",
    "IMAGE_DIR = ROOT_DIR + \"/Images/orgs/*.bmp\"\n",
    "points = glob.glob(POINTS_DIR)\n",
    "orgs = glob.glob(IMAGE_DIR)\n",
    "points.sort()\n",
    "orgs.sort()\n",
    "\n",
    "print(len(points))\n",
    "print(len(orgs))\n",
    "\n",
    "size = (128,128)\n",
    "\n",
    "imgs = []\n",
    "for image in orgs:\n",
    "    im = cv2.imread(image)\n",
    "    im = im[:,:,0:1]/255\n",
    "    imgs.append(im)\n",
    "\n",
    "imgs = np.asarray(imgs)\n",
    "#imgs.reshape(128,128,1)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for f in points:\n",
    "    file = open(f,'r')\n",
    "    XY_ =np.array([list(map(float,l.split(' ')[1:])) for l in file.read().splitlines()])\n",
    "    file.close()\n",
    "    X_ = XY_[:,0].reshape(-1,50)\n",
    "    Y_ = XY_[:,1].reshape(-1,50)\n",
    "    X.append(X_)\n",
    "    Y.append(Y_)\n",
    "#    print(X_.shape)\n",
    "#    print(Y_.shape)\n",
    "\n",
    "X = np.asarray(X,dtype=np.float64)[:,0,:]\n",
    "Y = np.asarray(Y,dtype=np.float64)[:,0,:]\n",
    "\n",
    "print(imgs.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 100)\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "N_COMP = 37 #l. punktów po generowaniu PCA\n",
    "N_FEATURES = 100 #l. wszystkich współrzędnych (2*50)\n",
    "comp = []\n",
    "f = open('pca.dat','r')\n",
    "for row in range(N_COMP):\n",
    "    for col in range(N_FEATURES):\n",
    "        comp.append(float(f.readline()))\n",
    "f.close()\n",
    "comp = np.asarray(comp,dtype=np.float32).reshape(N_COMP,N_FEATURES)\n",
    "print(comp.shape)\n",
    "compX = comp[:,0::2]\n",
    "compY = comp[:,1::2]\n",
    "#print(comp)\n",
    "#print(compX)\n",
    "#print(compY)\n",
    "\n",
    "av = []\n",
    "f = open('mean.dat','r')# średni kształt wyliczony w contours\n",
    "for row in range(N_FEATURES):\n",
    "    av.append(float(f.readline()))\n",
    "f.close()\n",
    "av = np.asarray(av,dtype=np.float32).reshape(-1,N_FEATURES)\n",
    "print(av.shape)\n",
    "avX = av[:,0::2]\n",
    "avY = av[:,1::2]\n",
    "#print(av)\n",
    "#print(avX)\n",
    "#print(avY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   9248        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8192)         0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000)         8193000     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         1001000     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 37)           37037       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1001        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1001        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            1001        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            1001        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            1001        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            1001        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,530,275\n",
      "Trainable params: 9,530,275\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_COMP = 37\n",
    "N_FEATURES = 100\n",
    "\n",
    "def conv2d_block(\n",
    "    inputs, \n",
    "    filters=16, \n",
    "    kernel_size=(3,3), \n",
    "    activation='relu', \n",
    "    kernel_initializer= 'glorot_uniform',\n",
    "    padding='same'):\n",
    "    \n",
    "    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (inputs)\n",
    "    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (c)\n",
    "    return c\n",
    "\n",
    "def linear(w,comp,av):\n",
    "    \n",
    "    b = tf.constant(comp, shape=(N_COMP, N_FEATURES//2))\n",
    "    c = tf.constant(av, shape=(1, N_FEATURES//2))\n",
    "    d = tf.matmul(w, b) + c\n",
    "    return d\n",
    "\n",
    "\n",
    "NUM_LAYERS = 4\n",
    "FILTERS = 16\n",
    "NUM_ELEMENTS = 1000\n",
    "\n",
    "inputs = Input(size+(1,))\n",
    "\n",
    "x = inputs   \n",
    "\n",
    "for l in range(NUM_LAYERS):\n",
    "    x = conv2d_block(inputs=x, filters=FILTERS)\n",
    "    x = MaxPooling2D((2, 2)) (x)\n",
    "    FILTERS = FILTERS*2 \n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(NUM_ELEMENTS,activation='relu')(x)\n",
    "x = Dense(NUM_ELEMENTS,activation='relu')(x)\n",
    "\n",
    "w = Dense(N_COMP)(x)\n",
    "A = Dense(1)(x) # współczynniki pierwszego wiersza macierzy homografii (wsp x)\n",
    "B = Dense(1)(x)\n",
    "C = Dense(1)(x)\n",
    "D = Dense(1)(x) #współczynniki dla drugiego wiersza macierzy homografii (wsp y)\n",
    "E = Dense(1)(x)\n",
    "F = Dense(1)(x)\n",
    "\n",
    "'''ta sekcja zostaje zakomentowana'''\n",
    "# X_ = Lambda(linear,arguments={'comp':compx,'av':avX})(w)#pca.inverse transform+mean\n",
    "# Y_ = Lambda(linear,arguments={'comp':compY,'av':avY})(w)#pca.inverse transform+mean\n",
    "#\n",
    "# outX = Add()([Multiply()([A,X_]),Multiply()([B,Y_]),C])#wynik obliczeń razy macierz homografii\n",
    "# outY = Add()([Multiply()([D,X_]),Multiply()([E,Y_]),F])#wynik obliczeń razy macierz homografii\n",
    "''''''\n",
    "# w-pca.components\n",
    "# A-\n",
    "model = Model(inputs=[inputs],outputs=[w,A,B,C,D,E,F])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01),\n",
    "                loss='mse',\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()]\n",
    "                 )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'PCA'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PCA'''\n",
    "#PCA inverse transform\n",
    "\n",
    "# TESTED = 163\n",
    "# r = np.zeros((50,1),dtype=np.float32)\n",
    "# print(compX.shape)\n",
    "# for col in range(compX):\n",
    "#     r[col] = np.sum(compX[:,col]*X_projected[TESTED])\n",
    "# # print(r-X_recon[TESTED])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 50)\n"
     ]
    }
   ],
   "source": [
    "X_ = linear(w,compX,avX)\n",
    "Y_ = linear(w,compY,avY)\n",
    "outX = tf.math.multiply(A,X_)+tf.math.multiply(B,Y_)+C\n",
    "outY = tf.math.multiply(D,X_)+tf.math.multiply(E,Y_)+F\n",
    "print(outY.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'procrustes'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''procrustes'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 128, 128, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When feeding symbolic tensors to a model, we expect the tensors to have a static batch size. Got tensor with shape: (None, 37)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-4b2b6e05d8f7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimgs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mhistory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mA\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mB\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mC\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mD\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mE\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mvalidation_split\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PracaMagisterska/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m   1152\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1153\u001B[0m             \u001B[0mclass_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1154\u001B[0;31m             batch_size=batch_size)\n\u001B[0m\u001B[1;32m   1155\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1156\u001B[0m         \u001B[0;31m# Prepare validation data.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PracaMagisterska/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36m_standardize_user_data\u001B[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001B[0m\n\u001B[1;32m    619\u001B[0m                 \u001B[0mfeed_output_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    620\u001B[0m                 \u001B[0mcheck_batch_axis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# Don't enforce the batch size.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 621\u001B[0;31m                 exception_prefix='target')\n\u001B[0m\u001B[1;32m    622\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    623\u001B[0m             \u001B[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PracaMagisterska/lib/python3.7/site-packages/keras/engine/training_utils.py\u001B[0m in \u001B[0;36mstandardize_input_data\u001B[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001B[0m\n\u001B[1;32m     97\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'DataFrame'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mstandardize_single_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PracaMagisterska/lib/python3.7/site-packages/keras/engine/training_utils.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     97\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'DataFrame'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mstandardize_single_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/PracaMagisterska/lib/python3.7/site-packages/keras/engine/training_utils.py\u001B[0m in \u001B[0;36mstandardize_single_array\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     30\u001B[0m                 \u001B[0;34m'When feeding symbolic tensors to a model, we expect the '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m                 \u001B[0;34m'tensors to have a static batch size. '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m                 'Got tensor with shape: %s' % str(shape))\n\u001B[0m\u001B[1;32m     33\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: When feeding symbolic tensors to a model, we expect the tensors to have a static batch size. Got tensor with shape: (None, 37)"
     ]
    }
   ],
   "source": [
    "print(imgs.shape)\n",
    "history = model.fit(imgs,[w,A,B,C,D,E,F],epochs=100,batch_size=10,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTED = 1\n",
    "yyy = model.predict(imgs[TESTED:TESTED+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imgs[TESTED,:,:,0].copy()\n",
    "print(yyy[0].shape)\n",
    "\n",
    "for p in range(50):\n",
    "    if int(yyy[1][0,p]) >=128:\n",
    "        continue\n",
    "    if int(yyy[0][0,p]) >=128:\n",
    "        continue\n",
    "    im[int(yyy[0][0,p]),int(yyy[1][0,p])] = 0\n",
    "\n",
    "\n",
    "showImage(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}